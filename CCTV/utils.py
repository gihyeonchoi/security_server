# CCTV/utils.py
import cv2
import threading
import time
import queue
import os
from django.http import StreamingHttpResponse
from django.conf import settings
import json
import numpy as np
from collections import deque
from ultralytics import YOLO
import torch
from PIL import Image, ImageDraw, ImageFont
import clip
import threading
from datetime import datetime

# ì „ì—­ ì•Œë¦¼ í (ëª¨ë“  ì¸ìŠ¤í„´ìŠ¤ê°€ ê³µìœ )
GLOBAL_ALERT_QUEUE = queue.Queue(maxsize=100)
ALERT_LISTENERS = []  # SSE ë¦¬ìŠ¤ë„ˆë“¤ì„ ì €ì¥

class CameraStreamer:
    def __init__(self):
        self.cameras = {}
        self.global_lock = threading.Lock()
        self.active_streams = {}
        self.frame_queues = {}
        self.reader_threads = {}
        self.background_streaming = {}  # ë°±ê·¸ë¼ìš´ë“œ ìŠ¤íŠ¸ë¦¬ë° ìƒíƒœ ì¶”ì 
    
    def get_camera_stream(self, rtsp_url):
        # print(f"ğŸ” global_lock íšë“ ì‹œë„: {rtsp_url}")
        
        # ë½ íšë“ ì‹œë„ (íƒ€ì„ì•„ì›ƒ 5ì´ˆ)
        lock_acquired = self.global_lock.acquire(timeout=5.0)
        if not lock_acquired:
            # print(f"âŒ global_lock íšë“ ì‹¤íŒ¨ (íƒ€ì„ì•„ì›ƒ): {rtsp_url}")
            pass
            # ì„ì‹œë¡œ ê¸°ë³¸ ì¹´ë©”ë¼ ì •ë³´ ë°˜í™˜
            if rtsp_url not in self.cameras:
                self.cameras[rtsp_url] = {
                    'cap': None,
                    'is_connected': False,
                    'last_frame': None,
                    'fps_counter': 0,
                    'last_fps_time': time.time(),
                    'avg_fps': 0,
                    'tracker_count': 0,
                    'lock': threading.Lock(),
                    'stream_count': 0,
                    'reconnect_attempts': 0,
                    'last_reconnect_time': 0
                }
                self.frame_queues[rtsp_url] = queue.Queue(maxsize=5)
            return self.cameras[rtsp_url]
        
        try:
            # print(f"âœ… global_lock íšë“ ì„±ê³µ: {rtsp_url}")
            if rtsp_url not in self.cameras:
                self.cameras[rtsp_url] = {
                    'cap': None,
                    'is_connected': False,
                    'last_frame': None,
                    'fps_counter': 0,
                    'last_fps_time': time.time(),
                    'avg_fps': 0,
                    'tracker_count': 0,
                    'lock': threading.Lock(),
                    'stream_count': 0,
                    'reconnect_attempts': 0,
                    'last_reconnect_time': 0
                }
                # ê° ì¹´ë©”ë¼ë³„ í”„ë ˆì„ í ìƒì„± (ë°±ê·¸ë¼ìš´ë“œ ëª¨ë“œë¥¼ ìœ„í•´ ì•½ê°„ ë” í° í)
                self.frame_queues[rtsp_url] = queue.Queue(maxsize=5)
            return self.cameras[rtsp_url]
        finally:
            self.global_lock.release()
            # print(f"ğŸ”“ global_lock í•´ì œ: {rtsp_url}")
    
    def connect_camera(self, rtsp_url):
        """ì¹´ë©”ë¼ ì—°ê²° ê°œì„  - íƒ€ì„ì•„ì›ƒ ë‹¨ì¶• ë° ë¹„ë™ê¸° ì²˜ë¦¬"""
        camera_info = self.get_camera_stream(rtsp_url)
        
        with camera_info['lock']:
            # ì¬ì—°ê²° ì‹œë„ ì œí•œ
            current_time = time.time()
            if camera_info['reconnect_attempts'] >= 3:
                if current_time - camera_info['last_reconnect_time'] < 30:
                    return False
                else:
                    camera_info['reconnect_attempts'] = 0
            
            if camera_info['cap'] is None or not camera_info['is_connected']:
                try:
                    if camera_info['cap']:
                        camera_info['cap'].release()
                        time.sleep(0.1)
                    
                    # OpenCV ì„¤ì • ìµœì í™” - íƒ€ì„ì•„ì›ƒ ë‹¨ì¶•
                    cap = cv2.VideoCapture(rtsp_url, cv2.CAP_FFMPEG)
                    
                    # RTSP ìŠ¤íŠ¸ë¦¼ ìµœì í™” ì„¤ì •
                    cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)
                    cap.set(cv2.CAP_PROP_FPS, 25)
                    cap.set(cv2.CAP_PROP_FOURCC, cv2.VideoWriter_fourcc(*'H264'))
                    
                    # FFMPEG ì˜µì…˜ ì„¤ì • - íƒ€ì„ì•„ì›ƒ ë‹¨ì¶•
                    cap.set(cv2.CAP_PROP_OPEN_TIMEOUT_MSEC, 2000)  # 5000 -> 2000ms
                    cap.set(cv2.CAP_PROP_READ_TIMEOUT_MSEC, 2000)  # 5000 -> 2000ms
                    
                    if cap.isOpened():
                        # ì²« í”„ë ˆì„ í…ŒìŠ¤íŠ¸ (íƒ€ì„ì•„ì›ƒ ì¶”ê°€)
                        import threading
                        frame_result = [None, None]
                        
                        def read_frame():
                            ret, frame = cap.read()
                            frame_result[0] = ret
                            frame_result[1] = frame
                        
                        read_thread = threading.Thread(target=read_frame)
                        read_thread.start()
                        read_thread.join(timeout=2.0)  # 2ì´ˆ íƒ€ì„ì•„ì›ƒ
                        
                        if read_thread.is_alive() or not frame_result[0] or frame_result[1] is None:
                            cap.release()
                            camera_info['reconnect_attempts'] += 1
                            camera_info['last_reconnect_time'] = current_time
                            print(f"âš ï¸ ì¹´ë©”ë¼ ì—°ê²° ì‹¤íŒ¨ (íƒ€ì„ì•„ì›ƒ): {rtsp_url}")
                            return False
                        
                        camera_info['cap'] = cap
                        camera_info['is_connected'] = True
                        camera_info['reconnect_attempts'] = 0
                        
                        # í”„ë ˆì„ ì½ê¸° ìŠ¤ë ˆë“œ ì‹œì‘
                        if rtsp_url not in self.reader_threads or not self.reader_threads[rtsp_url].is_alive():
                            reader_thread = threading.Thread(
                                target=self._frame_reader_thread,
                                args=(rtsp_url,),
                                daemon=True
                            )
                            self.reader_threads[rtsp_url] = reader_thread
                            reader_thread.start()
                        
                        return True
                    else:
                        camera_info['reconnect_attempts'] += 1
                        camera_info['last_reconnect_time'] = current_time
                        return False
                except Exception as e:
                    print(f"Camera connection error: {e}")
                    if 'cap' in locals() and cap:
                        cap.release()
                    camera_info['reconnect_attempts'] += 1
                    camera_info['last_reconnect_time'] = current_time
                    return False
            return camera_info['is_connected']
    
    def _frame_reader_thread(self, rtsp_url):
        """ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ í”„ë ˆì„ì„ ì§€ì†ì ìœ¼ë¡œ ì½ì–´ì„œ íì— ì €ì¥"""
        camera_info = self.cameras.get(rtsp_url)
        frame_queue = self.frame_queues.get(rtsp_url)
        
        if not camera_info or not frame_queue:
            return
        
        consecutive_failures = 0
        
        while True:
            with camera_info['lock']:
                cap = camera_info['cap']
                if not cap or not camera_info['is_connected']:
                    break
                stream_count = camera_info['stream_count']
            
            # ë°±ê·¸ë¼ìš´ë“œ ìŠ¤íŠ¸ë¦¬ë° ëª¨ë“œì´ê±°ë‚˜ ì‹¤ì œ ì‹œì²­ìê°€ ìˆëŠ” ê²½ìš°ì—ë§Œ í”„ë ˆì„ ì½ê¸°
            is_background = self.background_streaming.get(rtsp_url, False)
            if stream_count <= 0 and not is_background:
                time.sleep(0.1)
                continue
            
            try:
                ret, frame = cap.read()
                
                if ret and frame is not None:
                    consecutive_failures = 0
                    
                    # ì´ì „ í”„ë ˆì„ ì œê±° (íê°€ ê°€ë“ ì°¬ ê²½ìš°)
                    try:
                        frame_queue.get_nowait()
                    except queue.Empty:
                        pass
                    
                    # ìƒˆ í”„ë ˆì„ ì¶”ê°€
                    try:
                        frame_queue.put_nowait(frame)
                    except queue.Full:
                        pass
                    
                    # FPS ê³„ì‚°
                    with camera_info['lock']:
                        camera_info['fps_counter'] += 1
                        current_time = time.time()
                        if current_time - camera_info['last_fps_time'] >= 1.0:
                            camera_info['avg_fps'] = camera_info['fps_counter']
                            camera_info['fps_counter'] = 0
                            camera_info['last_fps_time'] = current_time
                else:
                    consecutive_failures += 1
                    if consecutive_failures > 10:
                        with camera_info['lock']:
                            camera_info['is_connected'] = False
                            if camera_info['cap']:
                                camera_info['cap'].release()
                                camera_info['cap'] = None
                        break
                
                # ë°±ê·¸ë¼ìš´ë“œ ëª¨ë“œì—ì„œëŠ” ë” ì ì€ CPU ì‚¬ìš©ì„ ìœ„í•´ ëŒ€ê¸° ì‹œê°„ ì¡°ì •
                is_background_only = self.background_streaming.get(rtsp_url, False) and stream_count <= 1
                if is_background_only:
                    time.sleep(0.04)  # ë°±ê·¸ë¼ìš´ë“œ ì „ìš© ëª¨ë“œ: 25 FPS
                else:
                    time.sleep(0.001)  # ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ëª¨ë“œ: ê³ ì„±ëŠ¥
                
            except Exception as e:
                print(f"Frame reading error for {rtsp_url}: {e}")
                consecutive_failures += 1
                if consecutive_failures > 10:
                    print(f"âš ï¸ ì—°ì† ì‹¤íŒ¨ 10íšŒ ì´ˆê³¼ - ì¹´ë©”ë¼ ì—°ê²° í•´ì œ: {rtsp_url}")
                    with camera_info['lock']:
                        camera_info['is_connected'] = False
                        if camera_info['cap']:
                            try:
                                camera_info['cap'].release()
                            except:
                                pass
                            camera_info['cap'] = None
                    break
                time.sleep(0.5)  # ì—ëŸ¬ ì‹œ ì§§ì€ ëŒ€ê¸°
    
    def generate_frames(self, rtsp_url):
        # print(f"ğŸ¬ generate_frames ì‹œì‘: {rtsp_url}")
        
        try:
            # print(f"ğŸ” ì¹´ë©”ë¼ ì •ë³´ ê°€ì ¸ì˜¤ëŠ” ì¤‘...")
            camera_info = self.get_camera_stream(rtsp_url)
            # print(f"âœ… ì¹´ë©”ë¼ ì •ë³´ íšë“ ì™„ë£Œ")
            
            # print(f"ğŸ” í”„ë ˆì„ í ê°€ì ¸ì˜¤ëŠ” ì¤‘...")
            frame_queue = self.frame_queues.get(rtsp_url)
            # print(f"ğŸ“Š í”„ë ˆì„ í ìƒíƒœ: {frame_queue is not None}")
            
            # print(f"ğŸ”’ ì¹´ë©”ë¼ ë½ íšë“ ì‹œë„...")
            with camera_info['lock']:
                camera_info['stream_count'] += 1
                # print(f"ğŸ“ˆ stream_count ì¦ê°€: {camera_info['stream_count']}")
                
        except Exception as e:
            print(f"âŒ generate_frames ì´ˆê¸°í™” ì˜¤ë¥˜: {e}")
            import traceback
            traceback.print_exc()
            return
        
        last_frame = None
        error_count = 0
        
        try:
            while True:
                connection_result = self.connect_camera(rtsp_url)
                # print(f"ğŸ”Œ ì¹´ë©”ë¼ ì—°ê²° ìƒíƒœ: {connection_result}")
                
                if not connection_result:
                    # print(f"âŒ ì¹´ë©”ë¼ ì—°ê²° ì‹¤íŒ¨ - ì—ëŸ¬ í”„ë ˆì„ ì „ì†¡")
                    pass
                    yield (b'--frame\r\n'
                           b'Content-Type: image/jpeg\r\n\r\n' + 
                           self.get_error_frame("Camera Disconnected") + b'\r\n')
                    time.sleep(2)
                    continue
                
                try:
                    # íì—ì„œ ìµœì‹  í”„ë ˆì„ ê°€ì ¸ì˜¤ê¸° (íƒ€ì„ì•„ì›ƒ ì„¤ì •)
                    # print(f"ğŸ“¥ í”„ë ˆì„ íì—ì„œ ë°ì´í„° ëŒ€ê¸° ì¤‘...")
                    frame = frame_queue.get(timeout=0.5)
                    # print(f"âœ… í”„ë ˆì„ ìˆ˜ì‹  ì„±ê³µ: {frame.shape if frame is not None else 'None'}")
                    last_frame = frame
                    error_count = 0
                except queue.Empty:
                    # print(f"â° í”„ë ˆì„ í íƒ€ì„ì•„ì›ƒ (ì—ëŸ¬ ì¹´ìš´íŠ¸: {error_count + 1})")
                    pass
                    error_count += 1
                    if error_count > 10:
                        # 10íšŒ ì´ìƒ í”„ë ˆì„ì„ ëª» ë°›ìœ¼ë©´ ì—°ê²° ë¬¸ì œë¡œ íŒë‹¨
                        with camera_info['lock']:
                            camera_info['is_connected'] = False
                        yield (b'--frame\r\n'
                               b'Content-Type: image/jpeg\r\n\r\n' + 
                               self.get_error_frame("No Signal") + b'\r\n')
                        continue
                    elif last_frame is not None:
                        # ë§ˆì§€ë§‰ í”„ë ˆì„ ì¬ì‚¬ìš©
                        frame = last_frame
                    else:
                        continue
                
                # JPEG ì¸ì½”ë”© (í’ˆì§ˆ ì¡°ì •ìœ¼ë¡œ ë„¤íŠ¸ì›Œí¬ ë¶€í•˜ ê°ì†Œ)
                encode_param = [int(cv2.IMWRITE_JPEG_QUALITY), 70]
                _, buffer = cv2.imencode('.jpg', frame, encode_param)
                frame_bytes = buffer.tobytes()
                
                yield (b'--frame\r\n'
                       b'Content-Type: image/jpeg\r\n'
                       b'Content-Length: ' + f'{len(frame_bytes)}'.encode() + b'\r\n\r\n' + 
                       frame_bytes + b'\r\n')
                
                # í”„ë ˆì„ ë ˆì´íŠ¸ ì œì–´ (25 FPS)
                time.sleep(0.04)
                
        except GeneratorExit:
            pass
        finally:
            with camera_info['lock']:
                camera_info['stream_count'] -= 1
                # ë°±ê·¸ë¼ìš´ë“œ ìŠ¤íŠ¸ë¦¬ë°ì´ í™œì„±í™”ë˜ì–´ ìˆìœ¼ë©´ ì¹´ë©”ë¼ ë¦¬ì†ŒìŠ¤ ì •ë¦¬í•˜ì§€ ì•ŠìŒ
                is_background = self.background_streaming.get(rtsp_url, False)
                if camera_info['stream_count'] <= 0 and not is_background:
                    # ì›¹ ìŠ¤íŠ¸ë¦¼ì´ ëª¨ë‘ ì¢…ë£Œë˜ê³  ë°±ê·¸ë¼ìš´ë“œë„ ë¹„í™œì„±ì´ë©´ ì¹´ë©”ë¼ ì—°ê²° í•´ì œ
                    if camera_info['cap']:
                        camera_info['cap'].release()
                        camera_info['cap'] = None
                    camera_info['is_connected'] = False
                    
                    # í”„ë ˆì„ í ë¹„ìš°ê¸°
                    try:
                        while not frame_queue.empty():
                            frame_queue.get_nowait()
                    except:
                        pass
    
    def get_error_frame(self, message="Camera Error"):
        """ì—ëŸ¬ ë©”ì‹œì§€ê°€ í¬í•¨ëœ í”„ë ˆì„ ìƒì„±"""
        error_frame = np.zeros((480, 640, 3), dtype=np.uint8)
        
        # ë°°ê²½ìƒ‰ ì„¤ì • (ì–´ë‘ìš´ íšŒìƒ‰)
        error_frame.fill(30)
        
        # í…ìŠ¤íŠ¸ í¬ê¸° ê³„ì‚°
        font = cv2.FONT_HERSHEY_SIMPLEX
        font_scale = 1
        thickness = 2
        text_size = cv2.getTextSize(message, font, font_scale, thickness)[0]
        
        # í…ìŠ¤íŠ¸ ìœ„ì¹˜ ê³„ì‚° (ì¤‘ì•™)
        text_x = (error_frame.shape[1] - text_size[0]) // 2
        text_y = (error_frame.shape[0] + text_size[1]) // 2
        
        # í…ìŠ¤íŠ¸ ê·¸ë¦¬ê¸°
        cv2.putText(error_frame, message, (text_x, text_y), 
                   font, font_scale, (0, 0, 255), thickness)
        
        # íƒ€ì„ìŠ¤íƒ¬í”„ ì¶”ê°€
        timestamp = time.strftime("%Y-%m-%d %H:%M:%S")
        cv2.putText(error_frame, timestamp, (10, 30), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
        
        _, buffer = cv2.imencode('.jpg', error_frame)
        return buffer.tobytes()
    
    def get_camera_status(self, rtsp_url):
        camera_info = self.get_camera_stream(rtsp_url)
        with camera_info['lock']:
            return {
                'is_connected': camera_info['is_connected'],
                'avg_fps': camera_info['avg_fps'],
                'tracker_count': camera_info['tracker_count'],
                'stream_count': camera_info['stream_count'],
                'reconnect_attempts': camera_info['reconnect_attempts']
            }
    
    def cleanup_camera(self, rtsp_url):
        """ì¹´ë©”ë¼ ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        with self.global_lock:
            if rtsp_url in self.cameras:
                camera_info = self.cameras[rtsp_url]
                with camera_info['lock']:
                    if camera_info['cap']:
                        camera_info['cap'].release()
                        camera_info['cap'] = None
                    camera_info['is_connected'] = False
                
                # ìŠ¤ë ˆë“œ ì¢…ë£Œ ëŒ€ê¸°
                if rtsp_url in self.reader_threads:
                    thread = self.reader_threads[rtsp_url]
                    if thread.is_alive():
                        thread.join(timeout=2.0)
                    del self.reader_threads[rtsp_url]
                
                # í ì •ë¦¬
                if rtsp_url in self.frame_queues:
                    del self.frame_queues[rtsp_url]
                
                del self.cameras[rtsp_url]
    
    def start_background_streaming(self, rtsp_url):
        """ë°±ê·¸ë¼ìš´ë“œ ì—°ì† ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘"""
        print(f"ğŸ”„ ë°±ê·¸ë¼ìš´ë“œ ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘ ì‹œë„: {rtsp_url}")
        
        # ë½ íƒ€ì„ì•„ì›ƒìœ¼ë¡œ ë°ë“œë½ ë°©ì§€
        if self.global_lock.acquire(timeout=3.0):
            try:
                self.background_streaming[rtsp_url] = True
                print(f"ğŸ”„ ë°±ê·¸ë¼ìš´ë“œ ìŠ¤íŠ¸ë¦¬ë° í”Œë˜ê·¸ ì„¤ì •: {rtsp_url}")
            finally:
                self.global_lock.release()
        else:
            print(f"âš ï¸ ë°±ê·¸ë¼ìš´ë“œ ìŠ¤íŠ¸ë¦¬ë° ë½ íƒ€ì„ì•„ì›ƒ: {rtsp_url}")
            return False
            
        # ì¹´ë©”ë¼ ì—°ê²° í™•ì¸ ë° ìŠ¤íŠ¸ë¦¼ ì‹œì‘ (ë½ ì™¸ë¶€ì—ì„œ)
        if self.connect_camera(rtsp_url):
            print(f"âœ… ë°±ê·¸ë¼ìš´ë“œ ìŠ¤íŠ¸ë¦¬ë° í™œì„±í™”: {rtsp_url}")
            return True
        else:
            print(f"âŒ ë°±ê·¸ë¼ìš´ë“œ ìŠ¤íŠ¸ë¦¬ë° ì‹¤íŒ¨ (ì—°ê²° ë¶ˆê°€): {rtsp_url}")
            return False
    
    def stop_background_streaming(self, rtsp_url):
        """ë°±ê·¸ë¼ìš´ë“œ ì—°ì† ìŠ¤íŠ¸ë¦¬ë° ì¤‘ì§€"""
        with self.global_lock:
            if rtsp_url in self.background_streaming:
                self.background_streaming[rtsp_url] = False
                del self.background_streaming[rtsp_url]
                print(f"â¹ï¸ ë°±ê·¸ë¼ìš´ë“œ ìŠ¤íŠ¸ë¦¬ë° ì¤‘ì§€: {rtsp_url}")
    
    def is_background_streaming(self, rtsp_url):
        """ë°±ê·¸ë¼ìš´ë“œ ìŠ¤íŠ¸ë¦¬ë° ìƒíƒœ í™•ì¸"""
        return self.background_streaming.get(rtsp_url, False)
    
    def start_all_background_streaming(self):
        """ëª¨ë“  ì¹´ë©”ë¼ì˜ ë°±ê·¸ë¼ìš´ë“œ ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘"""
        from .models import Camera
        cameras = Camera.objects.all()
        
        for camera in cameras:
            try:
                self.start_background_streaming(camera.rtsp_url)
            except Exception as e:
                print(f"âŒ ì¹´ë©”ë¼ '{camera.name}' ë°±ê·¸ë¼ìš´ë“œ ìŠ¤íŠ¸ë¦¬ë° ì‹¤íŒ¨: {e}")
    
    def stop_all_background_streaming(self):
        """ëª¨ë“  ë°±ê·¸ë¼ìš´ë“œ ìŠ¤íŠ¸ë¦¬ë° ì¤‘ì§€"""
        rtsp_urls = list(self.background_streaming.keys())
        for rtsp_url in rtsp_urls:
            self.stop_background_streaming(rtsp_url)
    
    def cleanup_all_resources(self):
        """ëª¨ë“  ì¹´ë©”ë¼ ë¦¬ì†ŒìŠ¤ ì •ë¦¬ (ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ë°©ì§€)"""
        print("ğŸ§¹ ëª¨ë“  ì¹´ë©”ë¼ ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì‹œì‘...")
        
        # ëª¨ë“  ë°±ê·¸ë¼ìš´ë“œ ìŠ¤íŠ¸ë¦¬ë° ì¤‘ì§€
        self.stop_all_background_streaming()
        
        # ëª¨ë“  ì¹´ë©”ë¼ ì—°ê²° í•´ì œ
        with self.global_lock:
            rtsp_urls = list(self.cameras.keys())
            for rtsp_url in rtsp_urls:
                self.cleanup_camera(rtsp_url)
        
        print("âœ… ëª¨ë“  ì¹´ë©”ë¼ ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì™„ë£Œ")

class AIDetectionSystem:
    def __init__(self):
        self.yolo_model = None
        self.clip_model = None
        self.clip_preprocess = None
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        self.detection_threads = {}
        self.detection_active = {}
        self.screenshot_dir = os.path.join(settings.MEDIA_ROOT, 'screenshots')
        self.load_models()
        self.ensure_screenshot_dir()
        # ì „ì—­ í ì‚¬ìš©
        self.alert_queue = GLOBAL_ALERT_QUEUE
        # í•œê¸€ í°íŠ¸ ì„¤ì •
        self.setup_korean_font()

    def setup_korean_font(self):
        """í•œê¸€ í°íŠ¸ ì„¤ì •"""
        # Windows í™˜ê²½
        font_paths = [
            "C:/Windows/Fonts/malgun.ttf",  # ë§‘ì€ ê³ ë”•
            "C:/Windows/Fonts/gulim.ttc",   # êµ´ë¦¼
            "C:/Windows/Fonts/batang.ttc",  # ë°”íƒ•
            "/usr/share/fonts/truetype/nanum/NanumGothic.ttf",  # Linux
            "/System/Library/Fonts/AppleSDGothicNeo.ttc",  # macOS
        ]
        
        self.korean_font = None
        for font_path in font_paths:
            if os.path.exists(font_path):
                try:
                    self.korean_font = font_path
                    print(f"âœ… í•œê¸€ í°íŠ¸ ë¡œë“œ: {font_path}")
                    break
                except:
                    continue
        
        if not self.korean_font:
            print("âš ï¸ í•œê¸€ í°íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì˜ë¬¸ë§Œ í‘œì‹œë©ë‹ˆë‹¤.")
    
    def ensure_screenshot_dir(self):
        """ìŠ¤í¬ë¦°ìƒ· ì €ì¥ ë””ë ‰í† ë¦¬ ìƒì„±"""
        if not os.path.exists(self.screenshot_dir):
            os.makedirs(self.screenshot_dir, exist_ok=True)
    
    def load_models(self):
        """YOLO11 ë° CLIP ëª¨ë¸ ë¡œë“œ (ë””ë²„ê·¸ ì¶”ê°€)"""
        print("\nğŸ”§ AI ëª¨ë¸ ë¡œë“œ ì‹œì‘...")
        print(f"  - PyTorch ë²„ì „: {torch.__version__}")
        print(f"  - CUDA ì‚¬ìš© ê°€ëŠ¥: {torch.cuda.is_available()}")
        if torch.cuda.is_available():
            print(f"  - CUDA ë””ë°”ì´ìŠ¤: {torch.cuda.get_device_name(0)}")
        
        try:
            # ë¦¬ëˆ…ìŠ¤/ìš°ë¶„íˆ¬ í™˜ê²½ì—ì„œ ë””ìŠ¤í”Œë ˆì´ ì„œë²„ ì—†ì´ OpenCV ì‹¤í–‰ ì„¤ì •
            import platform
            if platform.system() == 'Linux':
                os.environ['DISPLAY'] = ':0'  # X11 ë””ìŠ¤í”Œë ˆì´ ì„¤ì •
                # í—¤ë“œë¦¬ìŠ¤ í™˜ê²½ì—ì„œ GUI ë°±ì—”ë“œ ë¹„í™œì„±í™”
                import matplotlib
                matplotlib.use('Agg')
            
            # YOLO11 ëª¨ë¸ ë¡œë“œ
            yolo_path = os.path.join(settings.BASE_DIR, 'CCTV', 'yolo11n.pt')
            print(f"  - YOLO ëª¨ë¸ ê²½ë¡œ: {yolo_path}")
            print(f"  - YOLO ëª¨ë¸ ì¡´ì¬: {os.path.exists(yolo_path)}")
            
            if os.path.exists(yolo_path):
                # í—¤ë“œë¦¬ìŠ¤ í™˜ê²½ì—ì„œ YOLO ëª¨ë¸ ë¡œë“œ ì‹œ verbose=False ì„¤ì •
                self.yolo_model = YOLO(yolo_path)
                # GPU ì‚¬ìš© ë¶ˆê°€ëŠ¥í•œ ê²½ìš° CPUë¡œ ê°•ì œ ì„¤ì •
                if not torch.cuda.is_available():
                    self.device = "cpu"
                print(f"âœ… YOLO11 ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {yolo_path} (device: {self.device})")
                
                # YOLO í´ë˜ìŠ¤ ì •ë³´ ì¶œë ¥
                if hasattr(self.yolo_model, 'model') and hasattr(self.yolo_model.model, 'names'):
                    print(f"  - YOLO í´ë˜ìŠ¤ ìˆ˜: {len(self.yolo_model.model.names)}")
                    print(f"  - YOLO ì£¼ìš” í´ë˜ìŠ¤: {list(self.yolo_model.model.names.values())[:10]}...")
            else:
                print(f"âŒ YOLO11 ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {yolo_path}")
            
            # CLIP ëª¨ë¸ ë¡œë“œ
            try:
                print(f"\n  - CLIP ëª¨ë¸ ë¡œë“œ ì¤‘...")
                self.clip_model, self.clip_preprocess = clip.load("ViT-B/32", device=self.device)
                print(f"âœ… CLIP ëª¨ë¸ ë¡œë“œ ì™„ë£Œ (device: {self.device})")
            except Exception as clip_error:
                # CLIP ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨ ì‹œ CPUë¡œ ì¬ì‹œë„
                print(f"âš ï¸ CLIP GPU ë¡œë“œ ì‹¤íŒ¨, CPUë¡œ ì¬ì‹œë„: {clip_error}")
                self.device = "cpu"
                self.clip_model, self.clip_preprocess = clip.load("ViT-B/32", device=self.device)
                print(f"âœ… CLIP ëª¨ë¸ CPU ë¡œë“œ ì™„ë£Œ")
            
        except Exception as e:
            print(f"âŒ AI ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
            # ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨ ì‹œì—ë„ ì‹œìŠ¤í…œì´ ê³„ì† ë™ì‘í•˜ë„ë¡ ì„¤ì •
            self.yolo_model = None
            self.clip_model = None
    
    def start_detection_for_camera(self, camera):
        """íŠ¹ì • ì¹´ë©”ë¼ì— ëŒ€í•œ íƒì§€ ì‹œì‘"""
        if camera.id not in self.detection_active:
            self.detection_active[camera.id] = True
            detection_thread = threading.Thread(
                target=self._detection_worker,
                args=(camera,),
                daemon=True
            )
            self.detection_threads[camera.id] = detection_thread
            detection_thread.start()
            print(f"ğŸ¯ ì¹´ë©”ë¼ '{camera.name}' íƒì§€ ì‹œì‘")
    
    def stop_detection_for_camera(self, camera_id):
        """íŠ¹ì • ì¹´ë©”ë¼ì— ëŒ€í•œ íƒì§€ ì¤‘ì§€"""
        if camera_id in self.detection_active:
            self.detection_active[camera_id] = False
            print(f"â¹ï¸ ì¹´ë©”ë¼ ID {camera_id} íƒì§€ ì¤‘ì§€")
    
    def _detection_worker(self, camera):
        """ì¹´ë©”ë¼ë³„ íƒì§€ ì›Œì»¤ ìŠ¤ë ˆë“œ - ìŠ¤íŠ¸ë¦¼ ê³µìœ  ë²„ì „"""
        # from .models import TargetLabel, DetectionLog
        
        print(f"\nğŸš€ íƒì§€ ì›Œì»¤ ì‹œì‘: ì¹´ë©”ë¼ '{camera.name}' (ID: {camera.id})")
        consecutive_failures = 0
        connection_retry_count = 0
        
        while self.detection_active.get(camera.id, False):
            try:
                # ë¨¼ì € ì¹´ë©”ë¼ ì—°ê²° í™•ì¸ (ê¸°ì¡´ ì—°ê²° ì¬ì‚¬ìš©)
                camera_info = camera_streamer.get_camera_stream(camera.rtsp_url)
                
                # ì—°ê²°ì´ ì—†ìœ¼ë©´ ìƒˆë¡œ ì—°ê²° ì‹œë„
                if not camera_info['is_connected']:
                    connection_retry_count += 1
                    
                    # 3íšŒ ì‹¤íŒ¨ ì‹œ ëŒ€ê¸° ì‹œê°„ ì¦ê°€
                    if connection_retry_count > 3:
                        print(f"âš ï¸ ì¹´ë©”ë¼ '{camera.name}' ì—°ê²° ì‹œë„ {connection_retry_count}íšŒ ì‹¤íŒ¨")
                        
                        # ìŠ¤íŠ¸ë¦¬ë° ì¤‘ì¸ì§€ í™•ì¸
                        if camera_info.get('stream_count', 0) > 0:
                            print(f"ğŸ“º ì¹´ë©”ë¼ '{camera.name}'ëŠ” ìŠ¤íŠ¸ë¦¬ë° ì¤‘ì…ë‹ˆë‹¤. ìŠ¤íŠ¸ë¦¼ ê³µìœ  ëŒ€ê¸°...")
                            time.sleep(2)  # ì§§ì€ ëŒ€ê¸° í›„ ì¬ì‹œë„
                            connection_retry_count = 0  # ì¹´ìš´í„° ë¦¬ì…‹
                            continue
                        else:
                            print(f"ğŸ”„ ì¹´ë©”ë¼ '{camera.name}' ë…ë¦½ ì—°ê²° ì‹œë„...")
                            # ìŠ¤íŠ¸ë¦¬ë°ì´ ì—†ìœ¼ë©´ ë…ë¦½ì ìœ¼ë¡œ ì—°ê²°
                            if camera_streamer.connect_camera(camera.rtsp_url):
                                print(f"âœ… ì¹´ë©”ë¼ '{camera.name}' ì—°ê²° ì„±ê³µ")
                                connection_retry_count = 0
                                consecutive_failures = 0
                            else:
                                print(f"âŒ ì¹´ë©”ë¼ '{camera.name}' ì—°ê²° ì‹¤íŒ¨, 30ì´ˆ ëŒ€ê¸°")
                                time.sleep(30)
                                continue
                    else:
                        # ì—°ê²° ì‹œë„
                        print(f"ğŸ”Œ ì¹´ë©”ë¼ '{camera.name}' ì—°ê²° ì‹œë„ {connection_retry_count}/3")
                        if camera_streamer.connect_camera(camera.rtsp_url):
                            connection_retry_count = 0
                            consecutive_failures = 0
                        else:
                            time.sleep(2)
                            continue
                else:
                    # ì—°ê²°ë˜ì–´ ìˆìœ¼ë©´ ì¹´ìš´í„° ë¦¬ì…‹
                    connection_retry_count = 0
                    consecutive_failures = 0
                
                # í”„ë ˆì„ íì—ì„œ ìµœì‹  í”„ë ˆì„ ê°€ì ¸ì˜¤ê¸°
                frame_queue = camera_streamer.frame_queues.get(camera.rtsp_url)
                if not frame_queue:
                    print(f"âš ï¸ ì¹´ë©”ë¼ '{camera.name}' í”„ë ˆì„ í ì—†ìŒ")
                    time.sleep(1)
                    continue
                
                # í”„ë ˆì„ ê°€ì ¸ì˜¤ê¸° (ê³µìœ ëœ íì—ì„œ)
                frame = None
                try:
                    # íƒ€ì„ì•„ì›ƒì„ ì§§ê²Œ ì„¤ì •í•˜ì—¬ ë¹ ë¥¸ ì¬ì‹œë„
                    frame = frame_queue.get(timeout=1.0)
                    
                    # íê°€ ë„ˆë¬´ ë§ì´ ìŒ“ì˜€ìœ¼ë©´ ìµœì‹  í”„ë ˆì„ë§Œ ì‚¬ìš©
                    queue_size = frame_queue.qsize()
                    if queue_size > 2:
                        print(f"ğŸ“¦ í í¬ê¸°: {queue_size}, ìµœì‹  í”„ë ˆì„ìœ¼ë¡œ ìŠ¤í‚µ")
                        while queue_size > 1:
                            try:
                                frame = frame_queue.get_nowait()
                                queue_size -= 1
                            except queue.Empty:
                                break
                    
                    if frame is not None:
                        print(f"ğŸ“¹ í”„ë ˆì„ íšë“: ì¹´ë©”ë¼ '{camera.name}' - í¬ê¸°: {frame.shape}")
                except queue.Empty:
                    # íê°€ ë¹„ì–´ìˆìœ¼ë©´ ìŠ¤íŠ¸ë¦¼ì´ í™œì„±í™”ë  ë•Œê¹Œì§€ ëŒ€ê¸°
                    if camera_info.get('stream_count', 0) > 0:
                        # ìŠ¤íŠ¸ë¦¬ë° ì¤‘ì´ë©´ í”„ë ˆì„ì„ ê¸°ë‹¤ë¦¼
                        print(f"â³ ì¹´ë©”ë¼ '{camera.name}' í”„ë ˆì„ ëŒ€ê¸° ì¤‘ (ìŠ¤íŠ¸ë¦¬ë° í™œì„±)")
                        time.sleep(0.5)
                        continue
                    else:
                        # ìŠ¤íŠ¸ë¦¬ë°ì´ ì—†ìœ¼ë©´ ë°±ê·¸ë¼ìš´ë“œ ëª¨ë“œ í™œì„±í™”
                        print(f"ğŸ”„ ì¹´ë©”ë¼ '{camera.name}' ë°±ê·¸ë¼ìš´ë“œ ëª¨ë“œ í™œì„±í™”")
                        camera_streamer.start_background_streaming(camera.rtsp_url)
                        time.sleep(2)
                        continue
                
                if frame is None:
                    time.sleep(0.5)
                    continue
                
                # íƒ€ê²Ÿ ë¼ë²¨ ê°€ì ¸ì˜¤ê¸°
                target_labels = list(camera.target_labels.all())
                if not target_labels:
                    print(f"âš ï¸ ì¹´ë©”ë¼ '{camera.name}'ì— íƒ€ê²Ÿ ë¼ë²¨ì´ ì—†ìŒ")
                    time.sleep(5)
                    continue
                
                print(f"ğŸ¯ íƒ€ê²Ÿ ë¼ë²¨ {len(target_labels)}ê°œë¡œ íƒì§€ ì‹œì‘")
                
                # ê°ì²´ íƒì§€ ìˆ˜í–‰
                detections = self._detect_objects(frame, target_labels)
                
                # íƒì§€ ê²°ê³¼ ì²˜ë¦¬
                if detections:
                    print(f"âœ¨ íƒì§€ ì™„ë£Œ! {len(detections)}ê°œ íƒ€ê²Ÿ ë°œê²¬")
                    for detection in detections:
                        self._process_detection(camera, frame, detection, target_labels)
                
                # íƒì§€ ê°„ê²© ì¡°ì • (ìŠ¤íŠ¸ë¦¬ë° ìƒíƒœì— ë”°ë¼)
                if camera_info.get('stream_count', 0) > 0:
                    # ìŠ¤íŠ¸ë¦¬ë° ì¤‘ì´ë©´ ë” ìì£¼ íƒì§€
                    time.sleep(1.0)
                else:
                    # ë°±ê·¸ë¼ìš´ë“œ ëª¨ë“œë©´ ê°„ê²© ì¦ê°€
                    time.sleep(2.0)
                
            except Exception as e:
                print(f"âŒ íƒì§€ ì›Œì»¤ ì˜¤ë¥˜ (ì¹´ë©”ë¼: {camera.name}): {e}")
                import traceback
                traceback.print_exc()
                time.sleep(2)
        
        print(f"ğŸ›‘ íƒì§€ ì›Œì»¤ ì¢…ë£Œ: ì¹´ë©”ë¼ '{camera.name}'")
    
    def _detect_objects(self, frame, target_labels):
        """í”„ë ˆì„ì—ì„œ ê°ì²´ íƒì§€ - ë°”ìš´ë”© ë°•ìŠ¤ ì •ë³´ í¬í•¨"""
        detections = []
        
        if self.yolo_model is None or self.clip_model is None:
            print("âš ï¸ ë””ë²„ê·¸: YOLO ë˜ëŠ” CLIP ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•ŠìŒ")
            return detections
        
        try:
            # YOLOë¡œ 1ì°¨ ê°ì²´ íƒì§€ (ë°”ìš´ë”© ë°•ìŠ¤ íšë“)
            results = self.yolo_model(frame, verbose=False)
            
            if not results or len(results) == 0:
                return detections
            
            yolo_result = results[0]
            
            if hasattr(yolo_result, 'boxes') and yolo_result.boxes is not None:
                boxes = yolo_result.boxes.xyxy.cpu().numpy()
                confidences = yolo_result.boxes.conf.cpu().numpy() if yolo_result.boxes.conf is not None else []
                
                # ì‹ ë¢°ë„ 0.72 ì´ìƒì¸ ë°”ìš´ë”© ë°•ìŠ¤ë§Œ ì‚¬ìš©
                high_conf_mask = confidences >= 0.6
                valid_boxes = boxes[high_conf_mask]
                valid_confidences = confidences[high_conf_mask]
                
                if len(valid_boxes) == 0:
                    return detections
                
                # ê° íƒ€ê²Ÿ ë¼ë²¨ì— ëŒ€í•´ CLIPìœ¼ë¡œ ë¶„ë¥˜
                for target_label in target_labels:
                    detected_boxes = []
                    
                    for idx, (box, yolo_conf) in enumerate(zip(valid_boxes, valid_confidences)):
                        x1, y1, x2, y2 = map(int, box)
                        cropped_region = frame[y1:y2, x1:x2]
                        
                        if cropped_region.size > 0:
                            # CLIPìœ¼ë¡œ í•´ë‹¹ ì˜ì—­ ë¶„ë¥˜
                            pil_crop = Image.fromarray(cv2.cvtColor(cropped_region, cv2.COLOR_BGR2RGB))
                            crop_tensor = self.clip_preprocess(pil_crop).unsqueeze(0).to(self.device)
                            
                            text_query = f"a photo of {target_label.label_name}"
                            text_token = clip.tokenize([text_query]).to(self.device)
                            
                            with torch.no_grad():
                                # íŠ¹ì§• ì¶”ì¶œ
                                crop_features = self.clip_model.encode_image(crop_tensor)
                                text_features = self.clip_model.encode_text(text_token)
                                
                                # L2 ì •ê·œí™” (ì¤‘ìš”!)
                                crop_features = crop_features / crop_features.norm(dim=-1, keepdim=True)
                                text_features = text_features / text_features.norm(dim=-1, keepdim=True)
                                
                                # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚° (ì´ì œ -1ì—ì„œ 1 ì‚¬ì´)
                                similarity = (crop_features @ text_features.T).cpu().numpy()[0][0]
                                
                                # 0-1 ë²”ìœ„ë¡œ ë³€í™˜ (ì„ íƒì )
                                similarity_normalized = (similarity + 1) / 2
                                
                                print(f"     CLIP ìœ ì‚¬ë„: ì›ë³¸={similarity:.3f}, ì •ê·œí™”={similarity_normalized:.3f}")
                            
                            # CLIP ì„ê³„ê°’ (ì •ê·œí™”ëœ ê°’ ê¸°ì¤€ìœ¼ë¡œ ì¡°ì •)
                            if similarity_normalized > 0.72:  # ì‹ ë¢°ë„.
                                # YOLO ì‹ ë¢°ë„ì™€ CLIP ìœ ì‚¬ë„ì˜ í‰ê·  ì‚¬ìš©
                                combined_confidence = (float(yolo_conf) + float(similarity_normalized)) / 2
                                
                                detected_boxes.append({
                                    'box': [x1, y1, x2, y2],
                                    'confidence': combined_confidence,  # ê²°í•©ëœ ì‹ ë¢°ë„
                                    'yolo_confidence': float(yolo_conf),
                                    'clip_similarity': float(similarity_normalized)
                                })
                                print(f"     âœ… Box{idx}: ë§¤ì¹­! (YOLO={yolo_conf:.2f}, CLIP={similarity_normalized:.2f}, ê²°í•©={combined_confidence:.2f})")
                    
                    # í•´ë‹¹ ë¼ë²¨ë¡œ ë¶„ë¥˜ëœ ê°ì²´ê°€ ìˆë‹¤ë©´ íƒì§€ ê²°ê³¼ì— ì¶”ê°€
                    if detected_boxes:
                        # í‰ê·  ì‹ ë¢°ë„ ê³„ì‚°
                        avg_confidence = sum(box['confidence'] for box in detected_boxes) / len(detected_boxes)
                        
                        detections.append({
                            'label': target_label,
                            'confidence': float(avg_confidence),  # 0-1 ë²”ìœ„
                            'count': len(detected_boxes),
                            'has_alert': target_label.has_alert,
                            'boxes': detected_boxes
                        })
                        
                        print(f"     ğŸ¯ ìµœì¢… íƒì§€: {len(detected_boxes)}ê°œ (í‰ê·  ì‹ ë¢°ë„: {avg_confidence:.1%})")
            
        except Exception as e:
            print(f"âŒ ê°ì²´ íƒì§€ ì˜¤ë¥˜: {e}")
            import traceback
            traceback.print_exc()
        
        return detections

    def _process_detection(self, camera, frame, detection, target_labels):
        """íƒì§€ ê²°ê³¼ ì²˜ë¦¬ - ë°”ìš´ë”© ë°•ìŠ¤ í¬í•¨ ìŠ¤í¬ë¦°ìƒ·"""
        from .models import DetectionLog
        
        try:
            print(f"\nğŸ“ íƒì§€ ê²°ê³¼ ì²˜ë¦¬:")
            print(f"  - ì¹´ë©”ë¼: {camera.name}")
            print(f"  - ê°ì²´: {detection['label'].display_name}")
            print(f"  - ê°œìˆ˜: {detection['count']}")
            print(f"  - ì‹ ë¢°ë„: {detection['confidence']:.3f}")
            print(f"  - ì•Œë¦¼ ì—¬ë¶€: {'ì˜ˆ' if detection['has_alert'] else 'ì•„ë‹ˆì˜¤'}")
            
            # ìŠ¤í¬ë¦°ìƒ· ì €ì¥ (has_alertì¸ ê²½ìš° + ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸°)
            screenshot_path = None
            if detection['has_alert']:
                # í”„ë ˆì„ì— ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸°
                annotated_frame = self._draw_detection_boxes(frame, detection)
                screenshot_path = self._save_screenshot_with_boxes(camera, annotated_frame, detection)
                
                if screenshot_path:
                    print(f"  - ğŸ“¸ ìŠ¤í¬ë¦°ìƒ· ì €ì¥ (ë°•ìŠ¤ í¬í•¨): {screenshot_path}")
                else:
                    print(f"  - âš ï¸ ìŠ¤í¬ë¦°ìƒ· ì €ì¥ ì‹¤íŒ¨")
            
            # íƒì§€ ë¡œê·¸ ì €ì¥
            log = DetectionLog.objects.create(
                camera=camera,
                camera_name=camera.name,
                camera_location=camera.location,
                detected_object=detection['label'].display_name,
                object_count=detection['count'],
                confidence=detection['confidence'],
                has_alert=detection['has_alert'],
                screenshot_path=screenshot_path
            )
            
            print(f"  - ğŸ’¾ DB ë¡œê·¸ ì €ì¥ ì™„ë£Œ (ID: {log.id})")
            
            # ì‹¤ì‹œê°„ ì•Œë¦¼ ì „ì†¡ (has_alertì¸ ê²½ìš°)
            if detection['has_alert']:
                self._send_realtime_alert(log)
                print(f"  - ğŸ“¢ ì‹¤ì‹œê°„ ì•Œë¦¼ ì „ì†¡ ì™„ë£Œ")
            
        except Exception as e:
            print(f"âŒ íƒì§€ ê²°ê³¼ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            import traceback
            traceback.print_exc()
    def _draw_detection_boxes(self, frame, detection):
        """í”„ë ˆì„ì— ë°”ìš´ë”© ë°•ìŠ¤ì™€ ë¼ë²¨ ê·¸ë¦¬ê¸° (í•œê¸€ ì§€ì›)"""
        # í”„ë ˆì„ ë³µì‚¬ (ì›ë³¸ ë³´ì¡´)
        annotated_frame = frame.copy()
        
        # OpenCV BGRì„ PIL RGBë¡œ ë³€í™˜
        frame_rgb = cv2.cvtColor(annotated_frame, cv2.COLOR_BGR2RGB)
        pil_image = Image.fromarray(frame_rgb)
        draw = ImageDraw.Draw(pil_image)
        
        # í°íŠ¸ ì„¤ì • (í•œê¸€ ì§€ì›)
        try:
            if self.korean_font:
                font = ImageFont.truetype(self.korean_font, 24)
                small_font = ImageFont.truetype(self.korean_font, 18)
            else:
                # ê¸°ë³¸ í°íŠ¸ (ì˜ë¬¸ë§Œ)
                font = ImageFont.load_default()
                small_font = font
        except:
            font = ImageFont.load_default()
            small_font = font
        
        # ìƒ‰ìƒ ì„¤ì •
        if detection['has_alert']:
            box_color = (255, 0, 0)  # ë¹¨ê°„ìƒ‰ (ê²½ê³ )
            text_bg_color = (255, 0, 0)
        else:
            box_color = (0, 255, 0)  # ì´ˆë¡ìƒ‰ (ì¼ë°˜)
            text_bg_color = (0, 255, 0)
        text_color = (255, 255, 255)  # í°ìƒ‰ í…ìŠ¤íŠ¸
        
        # ê° ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸°
        if 'boxes' in detection and detection['boxes']:
            for idx, box_info in enumerate(detection['boxes']):
                x1, y1, x2, y2 = box_info['box']
                confidence = box_info['confidence']
                
                # ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸° (ë‘ê»˜ 3)
                draw.rectangle([x1, y1, x2, y2], outline=box_color, width=3)
                
                # ë¼ë²¨ í…ìŠ¤íŠ¸ ì¤€ë¹„
                label_text = f"{detection['label'].display_name} {confidence*100:.1f}%"
                
                # í…ìŠ¤íŠ¸ í¬ê¸° ê³„ì‚°
                try:
                    bbox = draw.textbbox((x1, y1), label_text, font=font)
                    text_width = bbox[2] - bbox[0]
                    text_height = bbox[3] - bbox[1]
                except:
                    # textbboxê°€ ì—†ëŠ” ê²½ìš° (êµ¬ë²„ì „ Pillow)
                    text_width, text_height = draw.textsize(label_text, font=font)
                
                # í…ìŠ¤íŠ¸ ë°°ê²½ ê·¸ë¦¬ê¸°
                text_bg_y1 = max(0, y1 - text_height - 10)
                text_bg_y2 = y1
                draw.rectangle(
                    [x1, text_bg_y1, x1 + text_width + 10, text_bg_y2],
                    fill=text_bg_color
                )
                
                # í…ìŠ¤íŠ¸ ê·¸ë¦¬ê¸°
                draw.text(
                    (x1 + 5, text_bg_y1 + 2),
                    label_text,
                    font=font,
                    fill=text_color
                )
                
                # ë°•ìŠ¤ ë²ˆí˜¸ (ì—¬ëŸ¬ ê°œì¼ ê²½ìš°)
                if len(detection['boxes']) > 1:
                    box_num_text = f"#{idx+1}"
                    draw.text(
                        (x1 + 5, y1 + 5),
                        box_num_text,
                        font=small_font,
                        fill=box_color
                    )
        
        # ì „ì²´ ì •ë³´ í‘œì‹œ (ìš°ì¸¡ ìƒë‹¨)
        info_text = f"ì´ {detection['count']}ê°œ íƒì§€"
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        
        # ì •ë³´ ë°°ê²½
        info_bg_x1 = pil_image.width - 250
        info_bg_y1 = 10
        info_bg_x2 = pil_image.width - 10
        info_bg_y2 = 70
        
        draw.rectangle(
            [info_bg_x1, info_bg_y1, info_bg_x2, info_bg_y2],
            fill=(0, 0, 0, 180)  # ë°˜íˆ¬ëª… ê²€ì •
        )
        
        draw.text(
            (info_bg_x1 + 10, info_bg_y1 + 5),
            info_text,
            font=font,
            fill=(255, 255, 255)
        )
        
        draw.text(
            (info_bg_x1 + 10, info_bg_y1 + 30),
            timestamp,
            font=small_font,
            fill=(200, 200, 200)
        )
        
        # PIL ì´ë¯¸ì§€ë¥¼ OpenCV í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        annotated_frame = cv2.cvtColor(np.array(pil_image), cv2.COLOR_RGB2BGR)
        
        return annotated_frame
    
    def _save_screenshot_with_boxes(self, camera, annotated_frame, detection):
        """ë°”ìš´ë”© ë°•ìŠ¤ê°€ ê·¸ë ¤ì§„ ìŠ¤í¬ë¦°ìƒ· ì €ì¥"""
        try:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            # íŒŒì¼ëª…ì— í•œê¸€ í¬í•¨ ì‹œ ë¬¸ì œ ë°©ì§€
            safe_object_name = detection['label'].display_name.replace(' ', '_')
            # í•œê¸€ì„ ì˜ë¬¸ìœ¼ë¡œ ë³€í™˜í•˜ê±°ë‚˜ ID ì‚¬ìš©
            if not safe_object_name.isascii():
                safe_object_name = f"object_{detection['label'].id}"
            
            filename = f"{camera.id}_{timestamp}_{safe_object_name}.jpg"
            filepath = os.path.join(self.screenshot_dir, filename)
            
            # ìŠ¤í¬ë¦°ìƒ· ì €ì¥ (JPEG í’ˆì§ˆ 95)
            cv2.imwrite(filepath, annotated_frame, [cv2.IMWRITE_JPEG_QUALITY, 95])
            
            print(f"    ğŸ’¾ ìŠ¤í¬ë¦°ìƒ· ì €ì¥ ì™„ë£Œ: {filename}")
            return filepath
            
        except Exception as e:
            print(f"âŒ ìŠ¤í¬ë¦°ìƒ· ì €ì¥ ì˜¤ë¥˜: {e}")
            return None
    
    def _save_screenshot(self, camera, frame, detection):
        """ê¸°ì¡´ ìŠ¤í¬ë¦°ìƒ· ì €ì¥ í•¨ìˆ˜ (ë°”ìš´ë”© ë°•ìŠ¤ í¬í•¨ ë²„ì „ìœ¼ë¡œ ë¦¬ë‹¤ì´ë ‰íŠ¸)"""
        # ë°”ìš´ë”© ë°•ìŠ¤ë¥¼ ê·¸ë¦° í”„ë ˆì„ ìƒì„±
        annotated_frame = self._draw_detection_boxes(frame, detection)
        # ì €ì¥
        return self._save_screenshot_with_boxes(camera, annotated_frame, detection)
    
    def _send_realtime_alert(self, log):
        """ì‹¤ì‹œê°„ ì•Œë¦¼ ì „ì†¡ - ê°œì„ ëœ ë²„ì „"""
        try:
            alert_data = {
                'type': 'detection_alert',
                'id': log.id,
                'camera_name': log.camera_name,
                'camera_location': log.camera_location,
                'detected_object': log.detected_object,
                'object_count': log.object_count,
                'detected_at': log.detected_at.isoformat(),
                'has_screenshot': bool(log.screenshot_path),
                'confidence': log.confidence,
                'is_new': True  # ìƒˆ ì•Œë¦¼ í”Œë˜ê·¸
            }
            
            # ì „ì—­ íì— ì¶”ê°€
            try:
                # íê°€ ê°€ë“ ì°¬ ê²½ìš° ì˜¤ë˜ëœ í•­ëª© ì œê±°
                if self.alert_queue.full():
                    try:
                        self.alert_queue.get_nowait()
                    except queue.Empty:
                        pass
                
                self.alert_queue.put_nowait(alert_data)
                print(f"  âœ… ì•Œë¦¼ íì— ì¶”ê°€ ì„±ê³µ: {alert_data['detected_object']}")
                print(f"  ğŸ“Š í í¬ê¸°: {self.alert_queue.qsize()}/{self.alert_queue.maxsize}")
                
                # ëª¨ë“  SSE ë¦¬ìŠ¤ë„ˆì—ê²Œ ì¦‰ì‹œ ì•Œë¦¼ (ì„ íƒì )
                for listener in ALERT_LISTENERS:
                    try:
                        listener(alert_data)
                    except:
                        pass
                        
            except queue.Full:
                print(f"  âš ï¸ ì•Œë¦¼ íê°€ ê°€ë“ ì°¸")
            except Exception as e:
                print(f"  âŒ í ì¶”ê°€ ì˜¤ë¥˜: {e}")
                
        except Exception as e:
            print(f"âŒ ì‹¤ì‹œê°„ ì•Œë¦¼ ì „ì†¡ ì˜¤ë¥˜: {e}")
            import traceback
            traceback.print_exc()

    def get_alert_queue(self):
        """ì•Œë¦¼ í ë°˜í™˜"""
        return self.alert_queue
    
    def start_all_detections(self):
        """ëª¨ë“  í™œì„± ì¹´ë©”ë¼ì— ëŒ€í•œ íƒì§€ ì‹œì‘ (ìë™ ì‹œì‘ ëª¨ë“œ)"""
        from .models import Camera
        
        cameras = Camera.objects.all()
        started_count = 0
        
        for camera in cameras:
            # íƒ€ê²Ÿ ë¼ë²¨ì´ ìˆëŠ” ì¹´ë©”ë¼ì´ê±°ë‚˜, ìë™ ì‹œì‘ ëª¨ë“œì—ì„œëŠ” ëª¨ë“  ì¹´ë©”ë¼ ì‹œì‘
            if camera.target_labels.exists():
                self.start_detection_for_camera(camera)
                started_count += 1
            else:
                print(f"âš ï¸ ì¹´ë©”ë¼ '{camera.name}'ì— íƒ€ê²Ÿ ë¼ë²¨ì´ ì—†ì–´ AI íƒì§€ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤")
        
        print(f"ğŸ¤– ì´ {started_count}ê°œ ì¹´ë©”ë¼ì—ì„œ AI íƒì§€ ì‹œì‘ë¨")
    
    def stop_all_detections(self):
        """ëª¨ë“  íƒì§€ ì¤‘ì§€"""
        for camera_id in list(self.detection_active.keys()):
            self.stop_detection_for_camera(camera_id)

# ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
camera_streamer = CameraStreamer()
ai_detection_system = AIDetectionSystem()

# ì•Œë¦¼ í ì ‘ê·¼ì„ ìœ„í•œ í—¬í¼ í•¨ìˆ˜
def get_global_alert_queue():
    """ì „ì—­ ì•Œë¦¼ í ë°˜í™˜"""
    return GLOBAL_ALERT_QUEUE