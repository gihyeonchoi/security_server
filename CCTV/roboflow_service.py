# CCTV/roboflow_service.py - InferencePipeline ì‚¬ìš© ë²„ì „
import asyncio
import base64
import json
import time
import cv2
import numpy as np
from typing import Dict, Any, List
from channels.layers import get_channel_layer
from asgiref.sync import async_to_sync
from django.conf import settings
from .models import CameraConfig

try:
    from inference import InferencePipeline
except ImportError:
    print("Warning: inference package not installed. Install with: pip install inference")
    InferencePipeline = None

class AsyncInferencePipelineManager:
    """InferencePipelineì„ ì‚¬ìš©í•œ ë¹„ë™ê¸° ì¹´ë©”ë¼ ìŠ¤íŠ¸ë¦¼ ê´€ë¦¬ì"""
    
    def __init__(self):
        self.pipelines: Dict[int, InferencePipeline] = {}
        self.active_connections: Dict[int, List] = {}  # ì¹´ë©”ë¼ë³„ WebSocket ì—°ê²° ê´€ë¦¬
        self.channel_layer = get_channel_layer()
        
    async def start_camera_pipeline(self, camera_id: int):
        """íŠ¹ì • ì¹´ë©”ë¼ì˜ InferencePipeline ì‹œì‘"""
        if camera_id in self.pipelines:
            print(f"ì¹´ë©”ë¼ {camera_id} ì´ë¯¸ ì‹¤í–‰ ì¤‘")
            return
            
        try:
            camera = await self._get_camera_config(camera_id)
            if not camera:
                print(f"ì¹´ë©”ë¼ {camera_id} ì„¤ì •ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ")
                return
                
            print(f"ì¹´ë©”ë¼ {camera_id} ì„¤ì •:")
            # print(f"  - API Key: {camera.api_key[:10]}...")
            print(f"  - API Key: {camera.api_key}")
            print(f"  - Workspace: {camera.workspace_name}")
            print(f"  - Workflow: {camera.workflow_id}")
            print(f"  - RTSP URL: {camera.rtsp_url}")
            print(f"  - Max FPS: {camera.max_fps}")
                
            # ë¹„ë™ê¸° sink wrapper ìƒì„± (ìŠ¤ë ˆë“œ ì•ˆì „)
            def async_sink_wrapper(result, video_frame):
                print(f"ğŸ“¡ ì¹´ë©”ë¼ {camera_id} ê°ì§€ ê²°ê³¼ ìˆ˜ì‹ ")
                try:
                    # ë©”ì¸ ìŠ¤ë ˆë“œì˜ ì´ë²¤íŠ¸ ë£¨í”„ì—ì„œ ì‹¤í–‰
                    import threading
                    def run_in_main_thread():
                        import asyncio
                        try:
                            loop = asyncio.get_event_loop()
                            if loop.is_running():
                                # ì´ë¯¸ ì‹¤í–‰ ì¤‘ì¸ ë£¨í”„ì— ì¶”ê°€
                                asyncio.run_coroutine_threadsafe(
                                    self._handle_detection_result(camera_id, result, video_frame), 
                                    loop
                                )
                            else:
                                # ìƒˆ ë£¨í”„ ìƒì„±
                                loop.run_until_complete(
                                    self._handle_detection_result(camera_id, result, video_frame)
                                )
                        except RuntimeError:
                            # ë™ê¸°ì ìœ¼ë¡œ ì²˜ë¦¬
                            self._handle_detection_result_sync(camera_id, result, video_frame)
                    
                    # ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰
                    thread = threading.Thread(target=run_in_main_thread)
                    thread.daemon = True
                    thread.start()
                    
                except Exception as e:
                    print(f"âŒ Sink wrapper ì˜¤ë¥˜: {e}")
                    # ë™ê¸°ì ìœ¼ë¡œ ì²˜ë¦¬
                    self._handle_detection_result_sync(camera_id, result, video_frame)
            
            if InferencePipeline is None:
                print(f"âŒ InferencePipelineì´ ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ")
                return
            
            print(f"ğŸš€ ì¹´ë©”ë¼ {camera_id} InferencePipeline ì´ˆê¸°í™” ì¤‘...")
            
            # InferencePipeline ì´ˆê¸°í™” (ì‹¤ì œ RTSP ìŠ¤íŠ¸ë¦¼ ì‚¬ìš©)
            print(f"ğŸ” RTSP URL: {camera.rtsp_url}")
            
            pipeline = InferencePipeline.init_with_workflow(
                api_key=camera.api_key,
                workspace_name=camera.workspace_name,
                workflow_id=camera.workflow_id,
                video_reference=camera.rtsp_url,
                max_fps=camera.max_fps,
                on_prediction=async_sink_wrapper,
            )
            
            print(f"ğŸ”„ ì¹´ë©”ë¼ {camera_id} Pipeline ì‹œì‘ ì¤‘...")
            
            # Pipeline ì‹œì‘ (ë¹„ë™ê¸° ì²˜ë¦¬)
            def start_pipeline():
                try:
                    print(f"ğŸ“¹ ì¹´ë©”ë¼ {camera_id} Pipeline ì‹¤ì œ ì‹œì‘...")
                    pipeline.start()
                    print(f"âœ… ì¹´ë©”ë¼ {camera_id} Pipeline ì‹œì‘ ì™„ë£Œ")
                except Exception as e:
                    print(f"âŒ Pipeline ì‹œì‘ ì¤‘ ì˜¤ë¥˜: {e}")
                    import traceback
                    traceback.print_exc()
            
            # ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ Pipeline ì‹œì‘
            import threading
            pipeline_thread = threading.Thread(target=start_pipeline)
            pipeline_thread.daemon = True
            pipeline_thread.start()
            
            self.pipelines[camera_id] = pipeline
            print(f"ğŸš€ ì¹´ë©”ë¼ {camera_id} Pipeline ìŠ¤ë ˆë“œ ì‹œì‘ë¨")
            
        except Exception as e:
            print(f"âŒ ì¹´ë©”ë¼ {camera_id} Pipeline ì‹œì‘ ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
    
    async def stop_camera_pipeline(self, camera_id: int):
        """íŠ¹ì • ì¹´ë©”ë¼ì˜ InferencePipeline ì¤‘ì§€"""
        if camera_id not in self.pipelines:
            print(f"ì¹´ë©”ë¼ {camera_id} Pipelineì´ ì‹¤í–‰ ì¤‘ì´ ì•„ë‹˜")
            return
            
        try:
            pipeline = self.pipelines[camera_id]
            
            # Pipeline ì¤‘ì§€ (ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ)
            loop = asyncio.get_running_loop()
            await loop.run_in_executor(None, pipeline.terminate)
            
            del self.pipelines[camera_id]
            print(f"ğŸ›‘ ì¹´ë©”ë¼ {camera_id} Pipeline ì¤‘ì§€")
            
        except Exception as e:
            print(f"âŒ ì¹´ë©”ë¼ {camera_id} Pipeline ì¤‘ì§€ ì‹¤íŒ¨: {e}")
    
    async def start_all_active_cameras(self):
        """ëª¨ë“  í™œì„± ì¹´ë©”ë¼ì˜ Pipeline ì‹œì‘"""
        active_cameras = await self._get_active_cameras()
        
        tasks = []
        for camera in active_cameras:
            task = asyncio.create_task(self.start_camera_pipeline(camera.id))
            tasks.append(task)
        
        if tasks:
            await asyncio.gather(*tasks, return_exceptions=True)
            print(f"âœ… {len(tasks)}ê°œ ì¹´ë©”ë¼ Pipeline ì‹œì‘ ì™„ë£Œ")
    
    async def stop_all_cameras(self):
        """ëª¨ë“  ì¹´ë©”ë¼ì˜ Pipeline ì¤‘ì§€"""
        camera_ids = list(self.pipelines.keys())
        
        tasks = []
        for camera_id in camera_ids:
            task = asyncio.create_task(self.stop_camera_pipeline(camera_id))
            tasks.append(task)
        
        if tasks:
            await asyncio.gather(*tasks, return_exceptions=True)
            print(f"ğŸ›‘ {len(tasks)}ê°œ ì¹´ë©”ë¼ Pipeline ì¤‘ì§€ ì™„ë£Œ")
    
    async def _handle_detection_result(self, camera_id: int, result: Dict[Any, Any], video_frame):
        """ê°ì§€ ê²°ê³¼ ì²˜ë¦¬ ë° WebSocket ë¸Œë¡œë“œìºìŠ¤íŠ¸"""
        try:
            # ê°ì§€ ê²°ê³¼ íŒŒì‹±
            detections = self._parse_detection_result(result)
            
            # í”„ë ˆì„ì„ base64ë¡œ ì¸ì½”ë”© (ì„ íƒì‚¬í•­)
            frame_data = None
            if video_frame is not None:
                frame_data = self._encode_frame_to_base64(video_frame)
            
            # WebSocketìœ¼ë¡œ ë¸Œë¡œë“œìºìŠ¤íŠ¸
            await self._broadcast_to_websocket(camera_id, {
                'camera_id': camera_id,
                'timestamp': time.time(),
                'detections': detections,
                'frame_data': frame_data,
                'detection_count': len(detections)
            })
            
            print(f"ğŸ“¡ ì¹´ë©”ë¼ {camera_id}: {len(detections)}ê°œ ê°ì²´ ê°ì§€")
            
        except Exception as e:
            print(f"âŒ ê°ì§€ ê²°ê³¼ ì²˜ë¦¬ ì˜¤ë¥˜ (ì¹´ë©”ë¼ {camera_id}): {e}")
    
    def _handle_detection_result_sync(self, camera_id: int, result: Dict[Any, Any], video_frame):
        """ê°ì§€ ê²°ê³¼ ë™ê¸°ì  ì²˜ë¦¬ (fallback)"""
        try:
            # ê°ì§€ ê²°ê³¼ íŒŒì‹±
            detections = self._parse_detection_result(result)
            
            # í”„ë ˆì„ì„ base64ë¡œ ì¸ì½”ë”© (í•„ìˆ˜)
            frame_data = None
            if video_frame is not None:
                frame_data = self._encode_frame_to_base64(video_frame)
                if frame_data:
                    print(f"âœ… ì¹´ë©”ë¼ {camera_id} í”„ë ˆì„ ì¸ì½”ë”© ì„±ê³µ")
                else:
                    print(f"âŒ ì¹´ë©”ë¼ {camera_id} í”„ë ˆì„ ì¸ì½”ë”© ì‹¤íŒ¨")
            
            # Django Channels ë™ê¸°ì  ë¸Œë¡œë“œìºìŠ¤íŠ¸
            from asgiref.sync import async_to_sync
            from channels.layers import get_channel_layer
            
            channel_layer = get_channel_layer()
            if channel_layer:
                data = {
                    'camera_id': camera_id,
                    'timestamp': time.time(),
                    'detections': detections,
                    'frame_data': frame_data,
                    'detection_count': len(detections)
                }
                
                print(f"ğŸ“¤ ì¹´ë©”ë¼ {camera_id} WebSocket ë¸Œë¡œë“œìºìŠ¤íŠ¸ ì‹œë„...")
                
                try:
                    # ê°œë³„ ì¹´ë©”ë¼ ê·¸ë£¹ì— ë¸Œë¡œë“œìºìŠ¤íŠ¸
                    async_to_sync(channel_layer.group_send)(
                        f"camera_{camera_id}",
                        {
                            "type": "detection_update",
                            "data": data
                        }
                    )
                    print(f"âœ… ì¹´ë©”ë¼ {camera_id} ê°œë³„ ê·¸ë£¹ ë¸Œë¡œë“œìºìŠ¤íŠ¸ ì„±ê³µ")
                except Exception as e:
                    print(f"âŒ ì¹´ë©”ë¼ {camera_id} ê°œë³„ ê·¸ë£¹ ë¸Œë¡œë“œìºìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
                
                try:
                    # ë¼ì´ë¸Œ ë·° ê·¸ë£¹ì— ë¸Œë¡œë“œìºìŠ¤íŠ¸
                    async_to_sync(channel_layer.group_send)(
                        "live_view",
                        {
                            "type": "detection_update",
                            "data": data
                        }
                    )
                    print(f"âœ… ì¹´ë©”ë¼ {camera_id} ë¼ì´ë¸Œ ë·° ê·¸ë£¹ ë¸Œë¡œë“œìºìŠ¤íŠ¸ ì„±ê³µ")
                except Exception as e:
                    print(f"âŒ ì¹´ë©”ë¼ {camera_id} ë¼ì´ë¸Œ ë·° ê·¸ë£¹ ë¸Œë¡œë“œìºìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
            else:
                print(f"âŒ Channel layerê°€ ì—†ìŒ")
            
            print(f"ğŸ“¡ ì¹´ë©”ë¼ {camera_id}: {len(detections)}ê°œ ê°ì²´ ê°ì§€ (ë™ê¸°)")
            
        except Exception as e:
            print(f"âŒ ë™ê¸° ê°ì§€ ê²°ê³¼ ì²˜ë¦¬ ì˜¤ë¥˜ (ì¹´ë©”ë¼ {camera_id}): {e}")
            import traceback
            traceback.print_exc()
    
    def _parse_detection_result(self, result: Dict[Any, Any]) -> List[Dict]:
        """Roboflow ê°ì§€ ê²°ê³¼ íŒŒì‹±"""
        detections = []
        
        try:
            # InferencePipeline ê²°ê³¼ êµ¬ì¡°ì— ë§ê²Œ íŒŒì‹±
            if 'predictions' in result:
                predictions = result['predictions']
            elif isinstance(result, list):
                predictions = result
            else:
                predictions = [result]
            
            for prediction in predictions:
                if isinstance(prediction, dict):
                    detection = {
                        'class': prediction.get('class', 'unknown'),
                        'confidence': prediction.get('confidence', 0.0),
                        'x': prediction.get('x', 0),
                        'y': prediction.get('y', 0),
                        'width': prediction.get('width', 0),
                        'height': prediction.get('height', 0)
                    }
                    detections.append(detection)
                    
        except Exception as e:
            print(f"ê°ì§€ ê²°ê³¼ íŒŒì‹± ì˜¤ë¥˜: {e}")
            
        return detections
    
    def _encode_frame_to_base64(self, frame) -> str:
        """í”„ë ˆì„ì„ base64ë¡œ ì¸ì½”ë”©"""
        try:
            img_array = None
            
            if hasattr(frame, 'numpy_image'):
                # InferencePipelineì˜ VideoFrame ê°ì²´ì¸ ê²½ìš°
                img_array = frame.numpy_image
                print(f"VideoFrame í¬ê¸°: {img_array.shape}")
            elif hasattr(frame, 'image'):
                # ë‹¤ë¥¸ í˜•íƒœì˜ í”„ë ˆì„ ê°ì²´
                img_array = frame.image
                print(f"Frame image í¬ê¸°: {img_array.shape}")
            elif isinstance(frame, np.ndarray):
                # numpy arrayì¸ ê²½ìš°
                img_array = frame
                print(f"NumPy array í¬ê¸°: {img_array.shape}")
            else:
                print(f"ì•Œ ìˆ˜ ì—†ëŠ” í”„ë ˆì„ íƒ€ì…: {type(frame)}")
                return None
                
            if img_array is None:
                print("í”„ë ˆì„ ë°ì´í„°ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŒ")
                return None
            
            # ì´ë¯¸ì§€ í˜•íƒœ í™•ì¸ ë° ë³€í™˜
            if len(img_array.shape) == 3 and img_array.shape[2] == 3:
                # RGBë¥¼ BGRë¡œ ë³€í™˜ (OpenCV ì‚¬ìš©)
                if img_array.dtype != np.uint8:
                    img_array = (img_array * 255).astype(np.uint8)
                img_array = cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR)
            
            # JPEGë¡œ ì¸ì½”ë”©
            success, buffer = cv2.imencode('.jpg', img_array, [cv2.IMWRITE_JPEG_QUALITY, 85])
            
            if not success:
                print("JPEG ì¸ì½”ë”© ì‹¤íŒ¨")
                return None
            
            # base64 ì¸ì½”ë”©
            img_base64 = base64.b64encode(buffer).decode('utf-8')
            return f"data:image/jpeg;base64,{img_base64}"
            
        except Exception as e:
            print(f"í”„ë ˆì„ ì¸ì½”ë”© ì˜¤ë¥˜: {e}")
            import traceback
            traceback.print_exc()
            return None
    
    async def _broadcast_to_websocket(self, camera_id: int, data: Dict):
        """WebSocketìœ¼ë¡œ ë°ì´í„° ë¸Œë¡œë“œìºìŠ¤íŠ¸"""
        try:
            if self.channel_layer:
                # ê°œë³„ ì¹´ë©”ë¼ ê·¸ë£¹ì— ë¸Œë¡œë“œìºìŠ¤íŠ¸
                await self.channel_layer.group_send(
                    f"camera_{camera_id}",
                    {
                        "type": "detection_update",
                        "data": data
                    }
                )
                
                # ë¼ì´ë¸Œ ë·° ê·¸ë£¹ì—ë„ ë¸Œë¡œë“œìºìŠ¤íŠ¸
                await self.channel_layer.group_send(
                    "live_view",
                    {
                        "type": "detection_update",
                        "data": data
                    }
                )
                
        except Exception as e:
            print(f"WebSocket ë¸Œë¡œë“œìºìŠ¤íŠ¸ ì˜¤ë¥˜: {e}")
    
    async def _get_camera_config(self, camera_id: int):
        """ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì¹´ë©”ë¼ ì„¤ì • ì¡°íšŒ (ë¹„ë™ê¸°)"""
        from channels.db import database_sync_to_async
        
        @database_sync_to_async
        def get_camera():
            try:
                return CameraConfig.objects.get(id=camera_id, is_active=True)
            except CameraConfig.DoesNotExist:
                return None
        
        return await get_camera()
    
    async def _get_active_cameras(self):
        """í™œì„± ì¹´ë©”ë¼ ëª©ë¡ ì¡°íšŒ (ë¹„ë™ê¸°)"""
        from channels.db import database_sync_to_async
        
        @database_sync_to_async
        def get_cameras():
            return list(CameraConfig.objects.filter(is_active=True))
        
        return await get_cameras()
    
    def get_pipeline_status(self) -> Dict[int, str]:
        """í˜„ì¬ ì‹¤í–‰ ì¤‘ì¸ Pipeline ìƒíƒœ ë°˜í™˜"""
        return {
            camera_id: "running" 
            for camera_id in self.pipelines.keys()
        }
    


# ì „ì—­ ë§¤ë‹ˆì € ì¸ìŠ¤í„´ìŠ¤
pipeline_manager = AsyncInferencePipelineManager()


# í¸ì˜ í•¨ìˆ˜ë“¤
async def start_camera_detection(camera_id: int):
    """ì¹´ë©”ë¼ ê°ì§€ ì‹œì‘"""
    await pipeline_manager.start_camera_pipeline(camera_id)

async def stop_camera_detection(camera_id: int):
    """ì¹´ë©”ë¼ ê°ì§€ ì¤‘ì§€"""
    await pipeline_manager.stop_camera_pipeline(camera_id)

async def start_all_detection():
    """ëª¨ë“  í™œì„± ì¹´ë©”ë¼ ê°ì§€ ì‹œì‘"""
    await pipeline_manager.start_all_active_cameras()

async def stop_all_detection():
    """ëª¨ë“  ì¹´ë©”ë¼ ê°ì§€ ì¤‘ì§€"""
    await pipeline_manager.stop_all_cameras()

def get_detection_status() -> Dict[int, str]:
    """í˜„ì¬ ê°ì§€ ìƒíƒœ ì¡°íšŒ"""
    return pipeline_manager.get_pipeline_status()


# ì‚¬ìš© ì˜ˆì‹œ:
# import asyncio
# from CCTV.roboflow_service import pipeline_manager
# 
# async def main():
#     # ëª¨ë“  í™œì„± ì¹´ë©”ë¼ ì‹œì‘
#     await pipeline_manager.start_all_active_cameras()
#     
#     # íŠ¹ì • ì¹´ë©”ë¼ë§Œ ì‹œì‘
#     await pipeline_manager.start_camera_pipeline(1)
#     
#     # 10ì´ˆ ëŒ€ê¸°
#     await asyncio.sleep(10)
#     
#     # ëª¨ë“  ì¹´ë©”ë¼ ì¤‘ì§€
#     await pipeline_manager.stop_all_cameras()
# 
# # ì‹¤í–‰
# asyncio.run(main())